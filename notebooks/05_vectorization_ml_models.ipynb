{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import gensim.downloader as gensim_api\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_title_cleaned</th>\n",
       "      <th>review_text_cleaned</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>num_special_chars</th>\n",
       "      <th>review_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hey</td>\n",
       "      <td>what be there to say about a fantastic chocola...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tasty  nutritious in one easy to administer po...</td>\n",
       "      <td>my 15 monthold twin boy be not big fan of spin...</td>\n",
       "      <td>8</td>\n",
       "      <td>280</td>\n",
       "      <td>34</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely tasty</td>\n",
       "      <td>okay  so these little can be not cheap  but wh...</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a good daily roast</td>\n",
       "      <td>this coffee have become one of my daily favori...</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newman s own turkey  vegetable catfood</td>\n",
       "      <td>i have four cat with differ tastebudslikes  th...</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>have an artificial vanilla flavor</td>\n",
       "      <td>sorry but i be look for a nice madagascar vani...</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>still wait</td>\n",
       "      <td>i order this item in august and i be a premium...</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>expensive</td>\n",
       "      <td>do yourself a favor and go to the nearest supe...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>yucky vegetable smoothie addin</td>\n",
       "      <td>gerber change the recipe for the worse  this v...</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>love the idea  can not stand the smell</td>\n",
       "      <td>my dog and i both love zuke s  the mini natura...</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>37</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    review_title_cleaned  \\\n",
       "0                                                   hey    \n",
       "1      tasty  nutritious in one easy to administer po...   \n",
       "2                                       absolutely tasty   \n",
       "3                                     a good daily roast   \n",
       "4                 newman s own turkey  vegetable catfood   \n",
       "...                                                  ...   \n",
       "29995                  have an artificial vanilla flavor   \n",
       "29996                                        still wait    \n",
       "29997                                         expensive    \n",
       "29998                     yucky vegetable smoothie addin   \n",
       "29999            love the idea  can not stand the smell    \n",
       "\n",
       "                                     review_text_cleaned  title_length  \\\n",
       "0      what be there to say about a fantastic chocola...             1   \n",
       "1      my 15 monthold twin boy be not big fan of spin...             8   \n",
       "2      okay  so these little can be not cheap  but wh...             2   \n",
       "3      this coffee have become one of my daily favori...             4   \n",
       "4      i have four cat with differ tastebudslikes  th...             6   \n",
       "...                                                  ...           ...   \n",
       "29995  sorry but i be look for a nice madagascar vani...             5   \n",
       "29996  i order this item in august and i be a premium...             2   \n",
       "29997  do yourself a favor and go to the nearest supe...             1   \n",
       "29998  gerber change the recipe for the worse  this v...             4   \n",
       "29999  my dog and i both love zuke s  the mini natura...             8   \n",
       "\n",
       "       text_length  num_special_chars review_type  \n",
       "0               45                  3    positive  \n",
       "1              280                 34    positive  \n",
       "2              102                 20    positive  \n",
       "3               35                  4    positive  \n",
       "4               76                 15    positive  \n",
       "...            ...                ...         ...  \n",
       "29995           28                  1    negative  \n",
       "29996           43                 19    negative  \n",
       "29997           27                 11    negative  \n",
       "29998           51                  7    negative  \n",
       "29999          261                 37    negative  \n",
       "\n",
       "[30000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Merged/reviews_cleaned.csv\")\n",
    "\n",
    "df[\"review_title_cleaned\"] = df[\"review_title_cleaned\"].astype(str)\n",
    "df[\"review_text_cleaned\"] = df[\"review_text_cleaned\"].astype(str)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(data: pd.DataFrame, encoder: LabelEncoder, fit: bool = False):\n",
    "    features = data.drop(\"review_type\", axis=1)\n",
    "    labels = data.iloc[:, -1].to_numpy().reshape(-1, 1)\n",
    "\n",
    "    if fit:\n",
    "        target = encoder.fit_transform(labels)\n",
    "    else:\n",
    "        target = encoder.transform(labels)\n",
    "\n",
    "    return features, np.array(target)\n",
    "\n",
    "\n",
    "def build_model_pipe(\n",
    "    vectorizer: CountVectorizer, model: BaseEstimator, include_extra: bool = True\n",
    ") -> Pipeline:\n",
    "    column_transformer = ColumnTransformer(\n",
    "        [\n",
    "            (\"title_vectorizer\", vectorizer, \"review_title_cleaned\"),\n",
    "            (\"text_vectorizer\", vectorizer, \"review_text_cleaned\"),\n",
    "        ],\n",
    "        remainder=\"passthrough\" if include_extra else \"drop\",\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([(\"vectorize\", column_transformer), (\"classify\", model)])\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "train_df = df.sample(frac=0.8)\n",
    "X_train, y_train = split_X_y(train_df, encoder, fit=True)\n",
    "\n",
    "test_df = df.drop(train_df.index)\n",
    "X_test, y_test = split_X_y(test_df, encoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70      2018\n",
      "           1       0.61      0.71      0.65      1984\n",
      "           2       0.85      0.76      0.80      1998\n",
      "\n",
      "    accuracy                           0.72      6000\n",
      "   macro avg       0.73      0.72      0.72      6000\n",
      "weighted avg       0.73      0.72      0.72      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_bow_mnb_clf = build_model_pipe(\n",
    "    vectorizer=CountVectorizer(), model=MultinomialNB(), include_extra=False\n",
    ")\n",
    "\n",
    "pipe_bow_mnb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_bow_mnb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      2018\n",
      "           1       0.67      0.67      0.67      1984\n",
      "           2       0.82      0.79      0.81      1998\n",
      "\n",
      "    accuracy                           0.74      6000\n",
      "   macro avg       0.74      0.74      0.74      6000\n",
      "weighted avg       0.74      0.74      0.74      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_bow_xgb_clf = build_model_pipe(\n",
    "    vectorizer=CountVectorizer(max_features=35000),\n",
    "    model=XGBClassifier(),\n",
    "    include_extra=False,\n",
    ")\n",
    "\n",
    "pipe_bow_xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_bow_xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipe_bow_xgb_clf, \"../data/models/bow_xgb_clf.jlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73      2018\n",
      "           1       0.63      0.72      0.67      1984\n",
      "           2       0.85      0.78      0.81      1998\n",
      "\n",
      "    accuracy                           0.74      6000\n",
      "   macro avg       0.74      0.74      0.74      6000\n",
      "weighted avg       0.74      0.74      0.74      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_bbow_mnb_clf = build_model_pipe(\n",
    "    vectorizer=CountVectorizer(max_features=40000, binary=True),\n",
    "    model=MultinomialNB(),\n",
    "    include_extra=False,\n",
    ")\n",
    "\n",
    "pipe_bbow_mnb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_bbow_mnb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75      2018\n",
      "           1       0.66      0.68      0.67      1984\n",
      "           2       0.82      0.79      0.81      1998\n",
      "\n",
      "    accuracy                           0.74      6000\n",
      "   macro avg       0.74      0.74      0.74      6000\n",
      "weighted avg       0.74      0.74      0.74      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_bbow_xgb_clf = build_model_pipe(\n",
    "    vectorizer=CountVectorizer(max_features=45000, binary=True),\n",
    "    model=XGBClassifier(),\n",
    "    include_extra=False,\n",
    ")\n",
    "\n",
    "pipe_bbow_xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_bbow_xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71      2018\n",
      "           1       0.55      0.85      0.67      1984\n",
      "           2       0.95      0.59      0.72      1998\n",
      "\n",
      "    accuracy                           0.70      6000\n",
      "   macro avg       0.76      0.70      0.70      6000\n",
      "weighted avg       0.76      0.70      0.70      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_ngram_mnb_clf = build_model_pipe(\n",
    "    vectorizer=CountVectorizer(ngram_range=(2, 3)), model=MultinomialNB()\n",
    ")\n",
    "\n",
    "pipe_ngram_mnb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_ngram_mnb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ngram_xgb_clf = build_model_pipe(\n",
    "    vectorizer=CountVectorizer(ngram_range=(2, 5)), model=XGBClassifier()\n",
    ")\n",
    "\n",
    "pipe_ngram_xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_ngram_xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tfidf_mnb_clf = build_model_pipe(\n",
    "    vectorizer=TfidfVectorizer(), model=MultinomialNB(), include_extra=False\n",
    ")\n",
    "\n",
    "pipe_tfidf_mnb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_tfidf_mnb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tfidf_xgb_clf = build_model_pipe(\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(2, 5), max_features=400000),\n",
    "    model=XGBClassifier(),\n",
    ")\n",
    "\n",
    "pipe_tfidf_xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_tfidf_xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v: KeyedVectors = gensim_api.load(\"glove-twitter-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(text: str):\n",
    "    words = word_tokenize(text)\n",
    "    vectors = []\n",
    "    for it in words:\n",
    "        if it in w2v.key_to_index:\n",
    "            vectors.append(w2v[it])\n",
    "        else:\n",
    "            vectors.append([0.0] * 200)\n",
    "    return np.mean(vectors, axis=0).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = np.array(\n",
    "    [vectorize_sentence(it) for it in X_train[\"review_text_cleaned\"]]\n",
    ")\n",
    "X_test_vec = np.array([vectorize_sentence(it) for it in X_test[\"review_text_cleaned\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      2060\n",
      "           1       0.56      0.55      0.56      1998\n",
      "           2       0.68      0.71      0.70      1942\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.63      0.63      0.63      6000\n",
      "weighted avg       0.63      0.63      0.63      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "m = RidgeClassifier()\n",
    "m.fit(X_train_vec, y_train)\n",
    "y_pred = m.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65      2060\n",
      "           1       0.60      0.62      0.61      1998\n",
      "           2       0.71      0.70      0.70      1942\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.65      0.65      0.65      6000\n",
      "weighted avg       0.65      0.65      0.65      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = XGBClassifier()\n",
    "m.fit(X_train_vec, y_train)\n",
    "y_pred = m.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
