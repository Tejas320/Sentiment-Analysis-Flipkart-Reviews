{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-07-29 17:17:35 +05:30)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-07-29 17:18:54 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import (\n",
    "    activations,\n",
    "    callbacks,\n",
    "    preprocessing,\n",
    "    layers,\n",
    "    losses,\n",
    "    metrics,\n",
    "    models,\n",
    "    optimizers,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    RocCurveDisplay,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 156 ms (started: 2023-07-29 17:17:42 +05:30)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/Merged/reviews_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2023-07-29 17:17:42 +05:30)\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = 30_000\n",
    "MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-07-29 17:17:42 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def build_vectorizer() -> layers.TextVectorization:\n",
    "    vec = layers.TextVectorization(\n",
    "        max_tokens=MAX_FEATURES,\n",
    "        output_sequence_length=MAX_LEN,\n",
    "        pad_to_max_tokens=True,\n",
    "        encoding=\"int\",\n",
    "    )\n",
    "\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.55 s (started: 2023-07-29 17:17:45 +05:30)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = build_vectorizer()\n",
    "vectorizer.adapt(data[\"review_text_cleaned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text (InputLayer)           [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 200)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 128)          3840000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 200, 128)          98816     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 128)               98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4037761 (15.40 MB)\n",
      "Trainable params: 4037761 (15.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "time: 781 ms (started: 2023-07-29 17:17:49 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def build_model(vectorizer: layers.TextVectorization) -> models.Model:\n",
    "    text_input = keras.Input(shape=(1,), dtype=tf.string, name=\"text\")\n",
    "    X = vectorizer(text_input)\n",
    "    X = layers.Embedding(MAX_FEATURES, 128)(X)\n",
    "\n",
    "    X = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(X)\n",
    "    X = layers.Bidirectional(layers.LSTM(64))(X)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(X)\n",
    "\n",
    "    model = keras.Model(inputs=text_input, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=losses.categorical_crossentropy,\n",
    "        optimizer=optimizers.RMSprop(learning_rate=1e-3),\n",
    "        metrics=[metrics.AUC(name=\"auc\"), metrics.CategoricalAccuracy(name=\"acc\")],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(vectorizer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X does not contain any features, but OneHotEncoder is expecting 21000 features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\base.py:391\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     n_features \u001b[39m=\u001b[39m _num_features(X)\n\u001b[0;32m    392\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:313\u001b[0m, in \u001b[0;36m_num_features\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    312\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m with shape \u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(message)\n\u001b[0;32m    314\u001b[0m \u001b[39mreturn\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to find the number of features from X of type pandas.core.series.Series with shape (21000,)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m enc \u001b[39m=\u001b[39m OneHotEncoder()\n\u001b[0;32m      8\u001b[0m enc\u001b[39m.\u001b[39mfit(y_train\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m y_train \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39;49mtransform(y_train)\n\u001b[0;32m     11\u001b[0m y_test \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mtransform(y_test)\n\u001b[0;32m     12\u001b[0m y_val \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mtransform(y_val)\n",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1016\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[39m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m warn_on_unknown \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39min\u001b[39;00m {\n\u001b[0;32m   1013\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1014\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfrequent_if_exist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1015\u001b[0m }\n\u001b[1;32m-> 1016\u001b[0m X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[0;32m   1017\u001b[0m     X,\n\u001b[0;32m   1018\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[0;32m   1019\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1020\u001b[0m     warn_on_unknown\u001b[39m=\u001b[39;49mwarn_on_unknown,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1023\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drop_idx_after_grouping \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:180\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform\u001b[39m(\n\u001b[0;32m    172\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    173\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     ignore_category_indices\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m ):\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 180\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    181\u001b[0m     X_list, n_samples, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(\n\u001b[0;32m    182\u001b[0m         X, force_all_finite\u001b[39m=\u001b[39mforce_all_finite\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m     X_int \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_samples, n_features), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\sklearn\\base.py:394\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    393\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m reset \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 394\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mX does not contain any features, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is expecting \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    397\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    399\u001b[0m     \u001b[39m# If the number of features is not defined and reset=True,\u001b[39;00m\n\u001b[0;32m    400\u001b[0m     \u001b[39m# then we skip this check\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: X does not contain any features, but OneHotEncoder is expecting 21000 features"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 296 ms (started: 2023-07-29 17:23:43 +05:30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[\"review_text_cleaned\"], data[\"review_type\"], train_size=0.7\n",
    ")\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=0.5)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train.to_numpy().reshape(1, -1))\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)\n",
    "y_val = enc.transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/Cast' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\trfdeer\\AppData\\Local\\Temp\\ipykernel_17224\\348381019.py\", line 8, in <module>\n      history = model.fit(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 2099, in categorical_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'categorical_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node categorical_crossentropy/Cast}}]] [Op:__inference_train_function_13184]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     callbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m      3\u001b[0m         monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_auc\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     ),\n\u001b[0;32m      5\u001b[0m     callbacks\u001b[39m.\u001b[39mReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_auc\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[0;32m      6\u001b[0m ]\n\u001b[1;32m----> 8\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      9\u001b[0m     X_train,\n\u001b[0;32m     10\u001b[0m     y_train,\n\u001b[0;32m     11\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val),\n\u001b[0;32m     12\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m,\n\u001b[0;32m     13\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/Cast' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\trfdeer\\AppData\\Local\\Temp\\ipykernel_17224\\348381019.py\", line 8, in <module>\n      history = model.fit(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\wrkspc\\projects\\xebia_internship\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 2099, in categorical_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'categorical_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node categorical_crossentropy/Cast}}]] [Op:__inference_train_function_13184]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.58 s (started: 2023-07-29 17:17:57 +05:30)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor=\"val_auc\", mode=\"max\", patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\", factor=0.7, patience=4),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=60,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist, metric='auc'):\n",
    "    plt.plot(hist.history[metric])\n",
    "    plt.plot(hist.history[\"val_\" + metric])\n",
    "    plt.title(f\"model performance\")\n",
    "    plt.ylabel(\"area_under_curve\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
