{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\trfdeer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\trfdeer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trfdeer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\trfdeer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey!</td>\n",
       "      <td>Whats there to say about a fantastic chocolate...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tasty &amp; Nutritious in one easy to administer p...</td>\n",
       "      <td>My 15 month-old twin boys aren't big fans of s...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolutely Tasty</td>\n",
       "      <td>Okay, so these little cans aren't cheap, but w...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Good Daily Roast</td>\n",
       "      <td>This coffee has become one of my daily favorit...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newman's Own Turkey &amp; Vegetable Catfood</td>\n",
       "      <td>I have four cats with differing tastebuds/like...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Has an artificial vanilla flavor</td>\n",
       "      <td>Sorry but I was looking for a nice madagascar ...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Still waiting.......</td>\n",
       "      <td>I ordered this item in AUGUST and i am a premi...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Expensive!</td>\n",
       "      <td>Do yourself a favor and go to the nearest supe...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Yucky Vegetable Smoothie Add-in</td>\n",
       "      <td>Gerber changed the recipe for the worse, this ...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Love the idea, can't stand the smell!</td>\n",
       "      <td>My dog and I both love Zuke's.  The mini natur...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_title  \\\n",
       "0                                                   Hey!   \n",
       "1      Tasty & Nutritious in one easy to administer p...   \n",
       "2                                       Absolutely Tasty   \n",
       "3                                     A Good Daily Roast   \n",
       "4                Newman's Own Turkey & Vegetable Catfood   \n",
       "...                                                  ...   \n",
       "29995                   Has an artificial vanilla flavor   \n",
       "29996                               Still waiting.......   \n",
       "29997                                         Expensive!   \n",
       "29998                    Yucky Vegetable Smoothie Add-in   \n",
       "29999              Love the idea, can't stand the smell!   \n",
       "\n",
       "                                             review_text  review_rating  \\\n",
       "0      Whats there to say about a fantastic chocolate...              5   \n",
       "1      My 15 month-old twin boys aren't big fans of s...              5   \n",
       "2      Okay, so these little cans aren't cheap, but w...              5   \n",
       "3      This coffee has become one of my daily favorit...              5   \n",
       "4      I have four cats with differing tastebuds/like...              5   \n",
       "...                                                  ...            ...   \n",
       "29995  Sorry but I was looking for a nice madagascar ...              1   \n",
       "29996  I ordered this item in AUGUST and i am a premi...              1   \n",
       "29997  Do yourself a favor and go to the nearest supe...              1   \n",
       "29998  Gerber changed the recipe for the worse, this ...              2   \n",
       "29999  My dog and I both love Zuke's.  The mini natur...              2   \n",
       "\n",
       "      review_type  \n",
       "0        positive  \n",
       "1        positive  \n",
       "2        positive  \n",
       "3        positive  \n",
       "4        positive  \n",
       "...           ...  \n",
       "29995    negative  \n",
       "29996    negative  \n",
       "29997    negative  \n",
       "29998    negative  \n",
       "29999    negative  \n",
       "\n",
       "[30000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Merged/reviews_div.csv\")\n",
    "df[\"review_text\"] = df[\"review_text\"].astype(str)\n",
    "df[\"review_title\"] = df[\"review_title\"].astype(str)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "pats = [re.compile(\"<.*?>\")]\n",
    "\n",
    "\n",
    "def clean_text(text: str, remove_stopwords_only: bool = False) -> str:\n",
    "    if not remove_stopwords_only:\n",
    "        text = str(contractions.fix(text))\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        for pat in pats:\n",
    "            text = re.sub(pat, \"\", text)\n",
    "        words = [\n",
    "            lemmatizer.lemmatize(i, j[0].lower())\n",
    "            if j[0].lower() in [\"a\", \"n\", \"v\"]\n",
    "            else lemmatizer.lemmatize(i)\n",
    "            for i, j in pos_tag(word_tokenize(text))\n",
    "        ]\n",
    "        text = \" \".join(words)\n",
    "\n",
    "    if remove_stopwords_only:\n",
    "        text = text.translate(str.maketrans(\"\", \"\", punctuation))\n",
    "        words = [\n",
    "            word\n",
    "            for word in word_tokenize(text)\n",
    "            if (word.lower() not in stop or word.lower() in {\"go\", \"do\", \"no\", \"not\"})\n",
    "        ]\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30000/30000 [01:44<00:00, 285.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30000/30000 [00:13<00:00, 2184.88it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"review_text_cleaned\"] = df[\"review_text\"].progress_map(clean_text)\n",
    "df[\"review_title_cleaned\"] = df[\"review_title\"].progress_map(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/Merged/reviews_cleaned_nostop.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct_count(text):\n",
    "    return len(re.findall(rf\"[{punctuation}]\", text))\n",
    "\n",
    "\n",
    "df[\"num_special_chars\"] = df[\"review_text_cleaned\"].apply(get_punct_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30000/30000 [00:05<00:00, 5404.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30000/30000 [00:01<00:00, 22364.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"review_text_cleaned\"] = df[\"review_text_cleaned\"].progress_map(\n",
    "    lambda text: clean_text(text, remove_stopwords_only=True)\n",
    ")\n",
    "df[\"review_title_cleaned\"] = df[\"review_title_cleaned\"].progress_map(\n",
    "    lambda text: clean_text(text, remove_stopwords_only=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_length\"] = df[\"review_title_cleaned\"].apply(lambda title: len(title.split()))\n",
    "df[\"text_length\"] = df[\"review_text_cleaned\"].apply(lambda text: len(text.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"review_title_cleaned\",\n",
    "        \"review_text_cleaned\",\n",
    "        \"title_length\",\n",
    "        \"text_length\",\n",
    "        \"num_special_chars\",\n",
    "        \"review_type\",\n",
    "    ],\n",
    "]\n",
    "df.to_csv(\"../data/Merged/reviews_cleaned.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
